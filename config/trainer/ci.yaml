batch_size: 1
epochs: 1
deterministic: false
save_interval: 1
num_saved_imgs: 6
optim:
  _target_: torch.optim.Adam
  lr: 1e-4
  betas: [0.9, 0.999]
scheduler:
  _target_: torch.optim.lr_scheduler.MultiStepLR
  milestones: [3, 6, 9]
  gamma: 0.5

# Learning rates (generator / discriminator)
lrG: 1e-4
lrD: 1e-4
lr_gamma: 0.5
lr_milestone: 3

# Loss weights
l1_loss_w: 1.0
gan_loss_w: 0.005
gp_loss_w: 10

# Gradient checkpointing
num_gradient_checkpoint: 0

# Attention curve ordering
curve_order: raster

# Optional losses
use_lpips_loss: false
lpips_loss_w: 0.1
use_ssim_loss: false
ssim_loss_w: 0.1

# Discriminator / FiLM flags
use_multiscale_discriminator: false
use_film: false
