batch_size: 8
epochs: 12
optim:
  _target_: torch.optim.Adam
  lr: 1e-4
  betas: [0.9, 0.999]
scheduler:
  _target_: torch.optim.lr_scheduler.MultiStepLR
  milestones: [3, 6, 9]
  gamma: 0.5
